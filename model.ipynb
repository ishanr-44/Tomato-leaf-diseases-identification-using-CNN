{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import Counter\n",
    "\n",
    "# Paths to datasets\n",
    "train_data_dir = r'C:\\Users\\ishan\\PycharmProjects\\test1\\data\\train'\n",
    "val_data_dir = r'C:\\Users\\ishan\\PycharmProjects\\test1\\data\\val'\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "img_size = (224, 224)\n",
    "num_classes = 4\n",
    "\n",
    "# Load VGG19 as the base model\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Unfreeze last layers of VGG19 for fine-tuning\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Create the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Output layer for multiclass classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Data Augmentation for Training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Data Augmentation for Validation\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load validation data\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important for confusion matrix\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(\"vgg19_model.keras\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=3, verbose=1)\n",
    "\n",
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint, early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"vgg19_model_new.h5\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "877ac4aa4f4b0a49",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "    # Plot training and validation accuracy/loss\n",
    "def plot_metrics(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(history)\n",
    "\n",
    "# Evaluate the model using validation data\n",
    "model = load_model(\"vgg19_model_new.h5\")\n",
    "\n",
    "# Predict on validation data\n",
    "val_generator.reset()  # Ensure no shuffling issues\n",
    "predictions = model.predict(val_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = val_generator.classes\n",
    "class_labels = list(val_generator.class_indices.keys())\n",
    "\n",
    "# Manually calculate confusion matrix\n",
    "confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "for true, pred in zip(true_classes, predicted_classes):\n",
    "    confusion_matrix[true, pred] += 1\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n",
    "# Manually generate classification report\n",
    "print(\"Classification Report:\")\n",
    "total_per_class = Counter(true_classes)\n",
    "for i, class_name in enumerate(class_labels):\n",
    "    tp = confusion_matrix[i, i]\n",
    "    fp = confusion_matrix[:, i].sum() - tp\n",
    "    fn = confusion_matrix[i, :].sum() - tp\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    support = total_per_class[i]\n",
    "    print(f\"{class_name}: Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1_score:.2f}, Support: {support}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b3494156d83b47c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
